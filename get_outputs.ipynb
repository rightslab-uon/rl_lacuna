{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:08.384723Z",
     "start_time": "2024-09-16T09:37:06.883675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from processing.box_whisker_graphs import BoxWhiskerGraph, MeltDataframe\n",
    "from processing.clean_data import CleanData\n",
    "from processing.descriptive_stats import DescriptiveStats\n",
    "from processing.dispersion_graphs import DispersionGraph\n",
    "from processing.heatmap import Heatmap\n",
    "from processing.line_graphs import LineGraphs\n",
    "from processing.scatter_graphs import ScatterGraph\n",
    "from processing.time_split import TimeSplit"
   ],
   "id": "f637ea2a44cb1b3e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:08.391763Z",
     "start_time": "2024-09-16T09:37:08.388556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "# change the level depending on where the data is stored\n",
    "three_levels_up = os.path.abspath(os.path.join(CURRENT_PATH, '..', '..'))\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Variables to be adapted based on date coverage, time groups required, city,  and output path ",
   "id": "f96de6151f53f457"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:08.547138Z",
     "start_time": "2024-09-16T09:37:08.543722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# in my file system, I have saved each csv using the following format: \"data_004_020924_090924.csv\" - the date is the same as the date_coverage_for_data_path and 004 is one of the device IDs\n",
    "\n",
    "date_coverage_for_data_path = '020924_090924'\n",
    "prefixes = ['004', '008', '011', '015', '024', '029', '036', '041', '044', '071']\n",
    "\n",
    "# the number of groups per day relates to whether you want to split the timings up. 4 groups will result in the following timings: 00:00-06:00, 06:00-12:00, 12:00-18:00 and 18:00-24:00. \n",
    "number_of_groups_per_day = 8\n",
    "\n",
    "# adapt to the route to your directory\n",
    "DATA_PATH = f'{three_levels_up}/Data/Gurugram'\n",
    "OUTPUT_PATH = f'{three_levels_up}/Coding/outputs/one_week_ten_sites_8_groups_Gurugram_test'\n",
    "# this is additional information to add to the name regarding the location and the number of sites\n",
    "locations_text = f'{len(prefixes)}_gurugram'\n",
    "\n",
    "# prefixes = ['012', '017', '018', '030', '032', '047', '061', '062', '073', '086']\n",
    "# number_of_groups_per_day = 8\n",
    "# DATA_PATH = f'{four_levels_up}/Data/Patna'\n",
    "# OUTPUT_PATH = f'{four_levels_up}/Coding/outputs/one_week_ten_sites_8_groups_Patna_ppt'\n",
    "# locations_text = f'{len(prefixes)}_patna'\n",
    "\n",
    "# The current list of static ids for the two cities are summarised below (as of 13/09/24). These can be used for the prefixes if you have downloaded all the data.\n",
    "# Gurugram = ['004', '007', '008', '011', '014', '015', '020', '024', '029', '033', '036', '037', '038', '041', '044', '046', '051', '054', '055', '059', '071', '075', '094', '096']\n",
    "# Patna = ['012', '013', '016', '017', '018', '019', '021', '022', '025', '026', '027', '028', '030', '031', '032', '035', '043', '047', '048', '049', '052', '061', '062', '063', '064', '073', '077', '086', '099']"
   ],
   "id": "c361976fdb580210",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The below is only to be adapted if you do not want to include all the variables or to add new variables/time groups",
   "id": "af2f2d30aedbc7e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:08.720684Z",
     "start_time": "2024-09-16T09:37:08.551872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = []\n",
    "\n",
    "for prefix in prefixes:\n",
    "    data_file = f'{DATA_PATH}/data_{prefix}_{date_coverage_for_data_path}.csv'\n",
    "    dataframe = pd.read_csv(data_file)\n",
    "    sorted_dataframe = dataframe.sort_values(by='data_created_time')\n",
    "    dataframes.append(sorted_dataframe)\n",
    "\n",
    "column_containing_dates = 'data_created_time'\n",
    "variables_list = ['pm_25', 'pm_10', 'no2', 'co', 'temp', 'rh']\n",
    "\n",
    "locations_with_pm_25 = [s + '_pm_25' for s in prefixes]\n",
    "locations_with_pm_10 = [s + '_pm_10' for s in prefixes]\n",
    "locations_with_no2 = [s + '_no2' for s in prefixes]\n",
    "locations_with_co = [s + '_co' for s in prefixes]\n",
    "locations_with_temp = [s + '_temp' for s in prefixes]\n",
    "locations_with_rh = [s + '_rh' for s in prefixes]\n",
    "\n",
    "locations_with_pollutant = [locations_with_pm_25, locations_with_pm_10, locations_with_no2, locations_with_co,\n",
    "                            locations_with_temp, locations_with_rh]\n",
    "\n",
    "time_groups = ['day_of_week', 'group_time', 'hour']\n",
    "descriptive_stats_groups = ['mean', 'max', 'min', 'range', 'iqr', 'std']\n",
    "key_time_date_column = 'data_created_time'"
   ],
   "id": "8e4bdf96273adc38",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The below cleans each dataframe, gets the overall descriptive stats and splits the data according to the time split you applied earlier.",
   "id": "eb6275c853a45d4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:09.261484Z",
     "start_time": "2024-09-16T09:37:08.734143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time_split_multiple = []\n",
    "clean_dataframes = []\n",
    "overall_descriptive_stats = []\n",
    "for dataframe in dataframes:\n",
    "    clean_dataframe = CleanData(dataframe=dataframe).remove_anomalies()\n",
    "    clean_dataframes.append(clean_dataframe)\n",
    "    overall_descriptive_stats.append(\n",
    "        DescriptiveStats([clean_dataframe], variables_list, output_directory=OUTPUT_PATH).get_stats())\n",
    "\n",
    "    time_split_multiple.append(\n",
    "        TimeSplit(clean_dataframe, column_containing_dates, number_of_groups_per_day).split_dataframe())"
   ],
   "id": "f0646d1b0c36fac4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get scatter plots involving all the locations you have included. The variables here are the ones found to have the highest correlations, however, ['pm_25', 'pm_10', 'temp', 'rh'] could be replaced with variables_list.",
   "id": "621702dba7220315"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:10.729136Z",
     "start_time": "2024-09-16T09:37:09.292198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "combined_dataframe = pd.concat(clean_dataframes, ignore_index=True)\n",
    "ScatterGraph(combined_dataframe, ['pm_25', 'pm_10', 'temp', 'rh'], output_directory=OUTPUT_PATH, combined=True).scatter_graph()"
   ],
   "id": "4371280d66efabd0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   index      x      y        r2\n",
       "5      5   temp     rh  0.853351\n",
       "0      0  pm_25  pm_10  0.749033\n",
       "2      2  pm_25     rh  0.048221\n",
       "1      1  pm_25   temp  0.003716\n",
       "3      3  pm_10   temp  0.003483\n",
       "4      4  pm_10     rh  0.001910"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>temp</td>\n",
       "      <td>rh</td>\n",
       "      <td>0.853351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pm_25</td>\n",
       "      <td>pm_10</td>\n",
       "      <td>0.749033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pm_25</td>\n",
       "      <td>rh</td>\n",
       "      <td>0.048221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pm_25</td>\n",
       "      <td>temp</td>\n",
       "      <td>0.003716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pm_10</td>\n",
       "      <td>temp</td>\n",
       "      <td>0.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pm_10</td>\n",
       "      <td>rh</td>\n",
       "      <td>0.001910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get the descriptive stats dataframes for key timings",
   "id": "6fee69b12a9aad3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:12.099439Z",
     "start_time": "2024-09-16T09:37:10.845754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "descriptive_stats_dataframes_timings = []\n",
    "for timing in ['group_time', 'hour', 'date']:\n",
    "    descriptive_stats_dataframes_timings.append(DescriptiveStats(time_split_multiple, variables_list, time_group=timing,output_directory=OUTPUT_PATH).get_stats())"
   ],
   "id": "6fe97ef3dfa628df",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get the prefixed dataframes and scatter plots",
   "id": "a7ac760d3f6ae77a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:22.445807Z",
     "start_time": "2024-09-16T09:37:12.114395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prefixed_dataframes = []\n",
    "for clean_dataframe, prefix in zip(clean_dataframes, prefixes):\n",
    "    dataframe_prefixed = clean_dataframe.add_prefix(f'{prefix}_')\n",
    "    prefixed_dataframes.append(dataframe_prefixed.rename(columns={f'{prefix}_{key_time_date_column}': f'{\n",
    "        key_time_date_column}'}))\n",
    "    ScatterGraph(clean_dataframe, variables_list,\n",
    "                 output_directory=OUTPUT_PATH).scatter_graph()"
   ],
   "id": "3e9126069836e07b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Merge all the clean dataframes and sort by time and update it to include the time split",
   "id": "142320aeff87685d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:22.755056Z",
     "start_time": "2024-09-16T09:37:22.447837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_dataframe = prefixed_dataframes[0]\n",
    "# Iterate and merge\n",
    "for dataframe in prefixed_dataframes[1:]:\n",
    "    merged_dataframe = merged_dataframe.merge(dataframe, on=key_time_date_column, how='outer')\n",
    "\n",
    "merged_dataframe_sorted = merged_dataframe.sort_values(by=key_time_date_column)\n",
    "\n",
    "updated_merged_dataframe = TimeSplit(merged_dataframe_sorted, column_containing_dates,\n",
    "                                     number_of_groups_per_day).split_dataframe()\n"
   ],
   "id": "65660dc75b4ea681",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get line and box plots for each location and pollutant overall and for the breakdown by time group",
   "id": "35547fb296202825"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:37:38.482243Z",
     "start_time": "2024-09-16T09:37:22.832230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for location_with_pollutant, prefix in zip(locations_with_pollutant, prefixes):\n",
    "    LineGraphs(merged_dataframe_sorted, \n",
    "               location_with_pollutant, \n",
    "               'data_created_time',\n",
    "               locations=f'{locations_text}_{prefix}',\n",
    "               output_directory=OUTPUT_PATH).line_plot()\n",
    "\n",
    "    focused_dataframe = updated_merged_dataframe[location_with_pollutant]\n",
    "\n",
    "    value = location_with_pollutant[0][4:]\n",
    "\n",
    "    df_melted = focused_dataframe.melt(var_name='Device', value_name=value)\n",
    "\n",
    "    df_melted['Device'] = df_melted['Device'].str.replace(f'_{value}', '')\n",
    "\n",
    "    BoxWhiskerGraph(df_melted, \n",
    "                    value, \n",
    "                    'Device', \n",
    "                    locations=f'{locations_text}_{value}',\n",
    "                    output_directory=OUTPUT_PATH).box_whisker_graph()\n",
    "\n",
    "    for x_column in time_groups:      \n",
    "        melted_dataframe = MeltDataframe(updated_merged_dataframe, \n",
    "                                         'locations', \n",
    "                                         value, \n",
    "                                         x_column,\n",
    "                                         location_with_pollutant,\n",
    "                                         location_more_than_one=True).get_melted_dataframe()\n",
    "        \n",
    "        melted_dataframe['locations'] = melted_dataframe['locations'].str.replace(f'_{value}', '')\n",
    "\n",
    "        BoxWhiskerGraph(melted_dataframe, \n",
    "                        value, \n",
    "                        x_column, \n",
    "                        multiple='locations',\n",
    "                        locations=locations_text,\n",
    "                        output_directory=OUTPUT_PATH).box_whisker_graph()"
   ],
   "id": "708e18e55227fcd0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:38:00.945803Z",
     "start_time": "2024-09-16T09:37:38.562308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataframe in clean_dataframes:\n",
    "    LineGraphs(dataframe, \n",
    "               ['pm_25', 'pm_10', 'no2'], \n",
    "               'data_created_time', \n",
    "               output_directory=OUTPUT_PATH).line_plot()\n",
    "    \n",
    "    for variable in variables_list:\n",
    "        for group in time_groups:\n",
    "            BoxWhiskerGraph(dataframe, \n",
    "                            variable, \n",
    "                            group, \n",
    "                            output_directory=OUTPUT_PATH).box_whisker_graph()\n"
   ],
   "id": "8316cf64eb9e51d2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get heatmaps and dispersion plots across sites and for different timings",
   "id": "3fb943349e27902d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:40:06.174890Z",
     "start_time": "2024-09-16T09:38:01.028919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "updated_descriptive_stats_dataframes_timings = []\n",
    "for variable in variables_list:\n",
    "    for group_dataframe in descriptive_stats_dataframes_timings:\n",
    "        updated_descriptive_stats_dataframes_timings.append(group_dataframe[group_dataframe['variable'] == variable])\n",
    "    \n",
    "        for dataframe, group in zip(updated_descriptive_stats_dataframes_timings, ['group_time', 'hour', 'date']):\n",
    "            for descriptive_stat in descriptive_stats_groups:\n",
    "                DispersionGraph(dataframe, \n",
    "                                [descriptive_stat], \n",
    "                                group, locations_stat_variable=f'{locations_text}_{descriptive_stat}_{variable}',\n",
    "                                output_directory=OUTPUT_PATH).dispersion_graph()\n",
    "                \n",
    "                Heatmap(dataframe, \n",
    "                        descriptive_stat, \n",
    "                        group, \n",
    "                        'device_id', locations=f'{locations_text}_{descriptive_stat}_{variable}', output_directory=OUTPUT_PATH).heatmap_plot()\n"
   ],
   "id": "a4e2006713286d5d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:40:06.346111Z",
     "start_time": "2024-09-16T09:40:06.343605Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "94ae58e0c40aabe2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
